{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb314d06-f20c-4e2a-8f68-ebcc7b9e75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4e3eea84-3019-4ce1-bd46-6fc758323db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import initialize, compose\n",
    "import hydra\n",
    "\n",
    "from cgpos.utils.util import import_pkl, export_pkl, get_abs_dir, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945faf51-fbe6-4be0-a2be-8f42843ccc71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset hydra\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "# Load hydra params\n",
    "initialize(\"../conf/\", version_base=None)\n",
    "config = compose(config_name='main')\n",
    "# Init logger\n",
    "logging.basicConfig(level=logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34fbd69-0470-488b-a1fa-cfbcebe95203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from cgpos.models.multinomial_naive_bayes import ngrams, count_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a65f07-3aac-4e2d-91dd-cce297fc204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cgpos.utils.util:Importing /home/tejomay/cgpos/data/processed/cleaned.pkl\n",
      "INFO:cgpos.utils.util:Importing /home/tejomay/cgpos/data/processed/features.pkl\n",
      "INFO:cgpos.utils.util:Importing /home/tejomay/cgpos/data/reference/target_map.pkl\n"
     ]
    }
   ],
   "source": [
    "uid, text, targets = import_pkl(config.data.cleaned)\n",
    "features = import_pkl(config.data.features)\n",
    "target_map = import_pkl(config.reference.target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "5aa215ba-44be-405e-ad51-5f5a1e4448f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "7bbb1f6f-5bcd-4d2d-bad0-831595df1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multinomial_naive_bayes():\n",
    "    def __init__(self, alpha=1, ngram_range=(1,1)):\n",
    "        self.alpha = 1\n",
    "        self.ngram_range = ngram_range\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_grams = [count_vectors(word, self.ngram_range) for word in X]\n",
    "        N = len(y)\n",
    "        V = len(set(flatten(X_grams)))\n",
    "        n_classes = max(y) + 1\n",
    "        class_counts = [0] * n_classes\n",
    "        feature_counts = defaultdict(Counter)\n",
    "        for i in range(N):\n",
    "            class_i = y[i]\n",
    "            features_i = X_grams[i]\n",
    "            class_counts[class_i] += 1\n",
    "            feature_counts[class_i].update(features_i)\n",
    "\n",
    "        log_priors = [math.log(class_counts[class_i] / N) for class_i in range(n_classes)]\n",
    "\n",
    "        def create_default_factory(value):\n",
    "            return lambda: value\n",
    "        \n",
    "        log_likelihoods = defaultdict(defaultdict)\n",
    "        for class_i in range(n_classes):\n",
    "            feature_total = sum(feature_counts[class_i].values())\n",
    "            denominator = feature_total + self.alpha * V\n",
    "            for key, value in feature_counts[class_i].items():\n",
    "                numerator = value + self.alpha\n",
    "                log_likelihood = math.log(numerator / denominator)\n",
    "                log_likelihoods[class_i][key] = log_likelihood\n",
    "            laplace = math.log(self.alpha / denominator)\n",
    "            log_likelihoods[class_i].default_factory = create_default_factory(laplace)\n",
    "\n",
    "        self.V = V\n",
    "        self.n_classes = n_classes\n",
    "        self.class_counts = class_counts\n",
    "        self.feature_counts = feature_counts\n",
    "        self.log_priors = log_priors\n",
    "        self.log_likelihoods = log_likelihoods\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_grams = [ngrams(word, self.ngram_range) for word in X]\n",
    "        preds = []\n",
    "        for x in X_grams:\n",
    "            probs = self.log_priors.copy()\n",
    "            for gram in x:\n",
    "                for class_i in range(self.n_classes):\n",
    "                    probs[class_i] += self.log_likelihoods[class_i][gram]\n",
    "            max_prob = float(\"-inf\") \n",
    "            argmax = None\n",
    "            for i, prob in enumerate(probs):\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    argmax = i\n",
    "            preds.append(argmax)\n",
    "                    \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "292e958c-10a4-4f73-a156-4d0c98ea3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_i = 0\n",
    "X_train, X_test, text_train, text_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    np.array([\" \".join(syllables) for syllables in text]),\n",
    "    np.array([target[class_i] for target in targets]),\n",
    "    train_size=0.8, random_state=20\n",
    ")\n",
    "target_names = target_map[1][class_i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "492f9106-94d6-45ed-9061-47951254e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(lowercase=False, ngram_range=(1,1), token_pattern=r\"\\b\\w+\\b\")),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "43620058-1835-476c-9449-373d4d04ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = multinomial_naive_bayes(alpha=1.0, ngram_range=(1,1))\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "65874250-ad91-46ae-be96-43e8fc259c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187721101117669"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "a2292ccb-d1d9-44bc-9eeb-73bc7fdd1d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(lowercase=False, token_pattern=&#x27;\\\\b\\\\w+\\\\b&#x27;)),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(lowercase=False, token_pattern=&#x27;\\\\b\\\\w+\\\\b&#x27;)),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(lowercase=False, token_pattern=&#x27;\\\\b\\\\w+\\\\b&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(lowercase=False, token_pattern='\\\\b\\\\w+\\\\b')),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(lowercase=False, ngram_range=(1,1), token_pattern=r\"\\b\\w+\\b\")),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "X_train_skl = [\" \".join([str(syllable) for syllable in word]) for word in X_train]\n",
    "X_test_skl = [\" \".join([str(syllable) for syllable in word]) for word in X_test]\n",
    "text_clf.fit(X_train_skl[:i], y_train[:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "f11603e2-7d41-4ce4-bf8e-b1c358631c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25276297, -1.25276297, -1.94591015, -1.25276297],\n",
       "       [-1.60943791, -1.60943791, -0.91629073, -1.60943791]])"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf[1].feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "9c948b3d-acdc-42ae-82b7-5d6c689a6edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  2,  5,  8, 12,  5,  2,  1,  2])"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(X_test_skl[:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "6afb5922-606c-4708-ace0-0da48adab177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_test[:j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "ce6aca09-a1cb-436a-b3b6-ef5475049c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.defaultdict,\n",
       "            {5: defaultdict(<function __main__.multinomial_naive_bayes.fit.<locals>.create_default_factory.<locals>.<lambda>()>,\n",
       "                         {(365,): -1.252762968495368,\n",
       "                          (1349,): -1.252762968495368,\n",
       "                          (570,): -1.252762968495368}),\n",
       "             6: defaultdict(<function __main__.multinomial_naive_bayes.fit.<locals>.create_default_factory.<locals>.<lambda>()>,\n",
       "                         {(432,): -0.916290731874155})})"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.log_likelihoods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
