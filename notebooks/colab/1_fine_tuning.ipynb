{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4dc2d7bd-f0b2-4012-84d6-006406ae707c",
      "metadata": {
        "tags": [],
        "id": "4dc2d7bd-f0b2-4012-84d6-006406ae707c"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejomaygadgil/cgpos/blob/nn/notebooks/colab/1_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Op3eRH6CJW",
        "outputId": "5e039fe1-580a-4725-c8e9-33de1e0a0b2c"
      },
      "id": "E5Op3eRH6CJW",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "JbOYRQiW7LHl",
        "outputId": "ca5fc63a-a240-4eaa-e412-7827806a75f2"
      },
      "id": "JbOYRQiW7LHl",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=1b711ca76bbd8d01193b2003c0cf710b7a05cbbedf35ccdaa22697cbc5ff5e1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "073b0da2-89d3-453f-aa3b-bfa840e42ea1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "073b0da2-89d3-453f-aa3b-bfa840e42ea1",
        "outputId": "884b1abd-ea7d-4d12-cbde-dfe786558129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cgpos'...\n",
            "remote: Enumerating objects: 2264, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
            "remote: Total 2264 (delta 159), reused 162 (delta 90), pack-reused 2022\u001b[K\n",
            "Receiving objects: 100% (2264/2264), 101.88 MiB | 36.93 MiB/s, done.\n",
            "Resolving deltas: 100% (1405/1405), done.\n",
            "Collecting git+https://github.com/jtauber/greek-accentuation.git\n",
            "  Cloning https://github.com/jtauber/greek-accentuation.git to /tmp/pip-req-build-3mhajpfx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jtauber/greek-accentuation.git /tmp/pip-req-build-3mhajpfx\n",
            "  Resolved https://github.com/jtauber/greek-accentuation.git to commit 15ac5fd1cc82c8f9b91a4041f9b64399c9552097\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beta-code in /usr/local/lib/python3.10/dist-packages (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone -b nn https://github.com/tejomaygadgil/cgpos.git\n",
        "!pip install git+https://github.com/jtauber/greek-accentuation.git beta-code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/cgpos\n",
        "!make process_ft_data\n",
        "!python src/pretrain.py setup pt_cloud"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeJyUG2qJ6Wj",
        "outputId": "d2140a03-9e40-4112-a82b-de562614aa6f"
      },
      "id": "zeJyUG2qJ6Wj",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cgpos\n",
            "Initializing data directory\n",
            "make: Nothing to be done for 'process_ft_data'.\n",
            "2023-10-08 16:40:42,820 - __main__ - INFO - Pre-training setup:\n",
            "2023-10-08 16:40:47,388 - util - INFO - Imported /content/drive/MyDrive/Colab Notebooks/pt_syl.pkl\n",
            "2023-10-08 16:40:58,993 - util - INFO - Exported data/train/pt_params.pkl\n",
            "2023-10-08 16:40:58,999 - util - INFO - Exported data/train/pt_stoi.pkl\n",
            "2023-10-08 16:40:59,003 - util - INFO - Exported data/train/pt_itos.pkl\n",
            "2023-10-08 16:40:59,355 - util - INFO - Exported data/train/pt_train\n",
            "2023-10-08 16:40:59,363 - util - INFO - Exported data/train/pt_val\n",
            "2023-10-08 16:40:59,363 - __main__ - INFO - vocab_size: 17,016\n",
            "2023-10-08 16:40:59,363 - __main__ - INFO - train_size: 0.98\n",
            "2023-10-08 16:40:59,363 - __main__ - INFO - n_chunks: 500\n",
            "2023-10-08 16:40:59,363 - __main__ - INFO - Train set: 34,631,855 obs\n",
            "2023-10-08 16:40:59,363 - __main__ - INFO - Val set: 708,210 obs\n",
            "\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXPfH2o0ArXI",
        "outputId": "2219ad05-19b1-412a-a619-ffd9ffc82529"
      },
      "id": "lXPfH2o0ArXI",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 354 bytes | 354.00 KiB/s, done.\n",
            "From https://github.com/tejomaygadgil/cgpos\n",
            "   32f1fbb..dd63b67  nn         -> origin/nn\n",
            "Updating 32f1fbb..dd63b67\n",
            "Fast-forward\n",
            " src/util.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3c286351-a1ab-48a3-ae69-c62c04d693d1",
      "metadata": {
        "tags": [],
        "id": "3c286351-a1ab-48a3-ae69-c62c04d693d1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0c976812-5ef1-4b6e-b427-efdf4bceb443",
      "metadata": {
        "tags": [],
        "id": "0c976812-5ef1-4b6e-b427-efdf4bceb443"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from src.model import Transformer\n",
        "import src.config as cfg\n",
        "from src.util import read_pkl, encode, decode, get_batch, display_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "43bf11e9-ccd0-4a00-8cab-9bd5fa14a20f",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "43bf11e9-ccd0-4a00-8cab-9bd5fa14a20f",
        "outputId": "b1d7c419-f592-4c56-d9bf-dddbc76c2a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtejomaygadgil\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/cgpos/wandb/run-20231008_164128-rke7h8mi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tejomaygadgil/ncgpos_ft/runs/rke7h8mi' target=\"_blank\">fresh-paper-3</a></strong> to <a href='https://wandb.ai/tejomaygadgil/ncgpos_ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tejomaygadgil/ncgpos_ft' target=\"_blank\">https://wandb.ai/tejomaygadgil/ncgpos_ft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tejomaygadgil/ncgpos_ft/runs/rke7h8mi' target=\"_blank\">https://wandb.ai/tejomaygadgil/ncgpos_ft/runs/rke7h8mi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "params = read_pkl(cfg.pt_params)\n",
        "wandb.init(project=\"ncgpos_ft\", config=params)\n",
        "for param, value in params.items():\n",
        "    globals()[param] = value\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read encodings\n",
        "stoi = read_pkl(cfg.pt_stoi)\n",
        "itos = read_pkl(cfg.pt_itos)\n",
        "# Read data\n",
        "ft_syl = read_pkl(cfg.ft_syl)\n",
        "ft_targets = read_pkl(cfg.ft_targets)\n",
        "ft_targets_map = read_pkl(cfg.ft_targets_map)\n",
        "assert len(ft_syl) == len(ft_targets)\n",
        "# Process data\n",
        "default_stoi = defaultdict(lambda: 0, stoi) # Set to \"<UNK>\" if OOV\n",
        "tokens = []\n",
        "labels = []\n",
        "for i, word in enumerate(ft_syl):\n",
        "    for token in encode(default_stoi, word):\n",
        "        tokens.append(token)\n",
        "        labels.append(ft_targets[i][0])\n",
        "\n",
        "tokens = torch.tensor(tokens, dtype=torch.long)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n",
        "assert len(tokens) == len(labels)\n",
        "print(list(zip(ft_syl, ft_targets))[:5])\n",
        "print(list(zip(tokens.tolist(), labels.tolist()))[:10])\n",
        "# Train val split\n",
        "tokens_chunks = torch.split(tokens, len(tokens) // (n_chunks - 1))\n",
        "labels_chunks = torch.split(labels, len(labels) // (n_chunks - 1))\n",
        "l = [1] * int(n_chunks * train_size) + [0] * int(n_chunks * (1 - train_size))\n",
        "random.shuffle(l)\n",
        "train_tokens = torch.cat([tokens_chunks[i] for i, v in enumerate(l) if v])\n",
        "train_labels = torch.cat([labels_chunks[i] for i, v in enumerate(l) if v])\n",
        "val_tokens = torch.cat([tokens_chunks[i] for i, v in enumerate(l) if not v])\n",
        "val_labels = torch.cat([labels_chunks[i] for i, v in enumerate(l) if not v])\n",
        "\n",
        "print(f\"train_size: {train_size}\")\n",
        "print(f\"n_chunks: {n_chunks}\")\n",
        "print(f\"Train size: {len(train_tokens):,} obs\")\n",
        "print(f\"Val size: {len(val_tokens):,} obs\")\n",
        "display_bar(l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHD2dXPkGxpB",
        "outputId": "9bf9c0bf-3aa0-4607-9cad-adb352f96cd0"
      },
      "id": "sHD2dXPkGxpB",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['Θου', 'κυ', 'δί', 'δης'], [2, 0, 1, 0, 0, 0, 1, 1, 0]), (['Ἀ', 'θη', 'ναῖ', 'ος'], [2, 0, 1, 0, 0, 0, 1, 1, 0]), (['ξυ', 'νέ', 'γρα', 'ψε'], [5, 3, 1, 7, 1, 1, 0, 0, 0]), (['τὸν'], [1, 0, 1, 0, 0, 0, 1, 4, 0]), (['πό', 'λε', 'μον'], [2, 0, 1, 0, 0, 0, 1, 4, 0])]\n",
            "[(1025, 2), (7409, 2), (4853, 2), (5001, 2), (15916, 2), (5970, 2), (8861, 2), (9665, 2), (9519, 5), (8752, 5)]\n",
            "train_size: 0.98\n",
            "n_chunks: 500\n",
            "Train size: 1,095,328 obs\n",
            "Val size: 22,390 obs\n",
            "\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[41m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\n",
            "\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m\u001b[42m \u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "08d88270-5ba2-463e-aeed-bae16e4b3d95",
      "metadata": {
        "tags": [],
        "id": "08d88270-5ba2-463e-aeed-bae16e4b3d95"
      },
      "outputs": [],
      "source": [
        "model = Transformer(\n",
        "    vocab_size=17016,\n",
        "    block_size=256,\n",
        "    emb_size=512,\n",
        "    n_layer=6,\n",
        "    n_head=8,\n",
        "    dropout=0.6,\n",
        "    device=device\n",
        ")\n",
        "model.load_state_dict(torch.load(cfg.pt_wts, map_location=torch.device(device)))\n",
        "# Omg!!\n",
        "model.lm_head = nn.Linear(512, len(ft_targets_map[1][0]))\n",
        "\n",
        "m = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6e8db07a-9316-4357-88ad-b0050b295ad9",
      "metadata": {
        "id": "6e8db07a-9316-4357-88ad-b0050b295ad9"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss(eval_iters, device, *batch_args):\n",
        "    out = []\n",
        "    model.eval()\n",
        "    for tokens, labels in [(train_tokens, train_labels), (val_tokens, val_labels)]:\n",
        "        losses = torch.zeros(eval_iters, device=device)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(tokens, *batch_args, y=labels)\n",
        "            _, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out.append(losses.mean())\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_tokens\n"
      ],
      "metadata": {
        "id": "8dJMSYv7Ls-U"
      },
      "id": "8dJMSYv7Ls-U",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.to(device)"
      ],
      "metadata": {
        "id": "PRQFg1X_L8zq",
        "outputId": "12cf4b76-368f-4241-bc51-179e398c4872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "id": "PRQFg1X_L8zq",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-9946387c42b7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "x = torch.stack([data[i : i + block_size] for i in ix])\n"
      ],
      "metadata": {
        "id": "f1qp4LQBL6ie"
      },
      "id": "f1qp4LQBL6ie",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "x = torch.stack([data[i : i + block_size] for i in ix])\n",
        "x = x.to(device)\n",
        "y = y.to(device)\n",
        "return x\n"
      ],
      "metadata": {
        "id": "bsqkfyNFLpn6"
      },
      "id": "bsqkfyNFLpn6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(data, block_size, batch_size, device, y=None):\n",
        "    # Generate a small batch of data of inputs x and targets y\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
        "    if y is not None:\n",
        "        y = torch.stack([y[i + 1 : i + block_size + 1] for i in ix])\n",
        "    else:\n",
        "        y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    return x\n",
        "    # return x, y"
      ],
      "metadata": {
        "id": "w-1s2_bWLg09"
      },
      "id": "w-1s2_bWLg09",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch(train_tokens, block_size, batch_size, device, y=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "crzX2Zo9LPsd",
        "outputId": "e0a51a62-7f0d-4262-ac77-1a62386c25f9"
      },
      "id": "crzX2Zo9LPsd",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a129e12f7b35>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-df7d25acb4c8>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(data, block_size, batch_size, device, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "78631f67-3350-4af0-8ec6-713ec0cc51a9",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "78631f67-3350-4af0-8ec6-713ec0cc51a9",
        "outputId": "5e87145a-15cb-45f8-f40e-649b2d5dd130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b5e3a0c57567>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Sample batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cgpos/src/util.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(data, block_size, batch_size, device, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
        "for step in tqdm(range(max_iters)):\n",
        "    # Evaluate training and val loss every eval_interval\n",
        "    # if (step % eval_interval == 0) or (iter == max_iters - 1):\n",
        "    #     train_loss, val_loss = estimate_loss(\n",
        "    #         eval_iters, device, block_size, batch_size, device\n",
        "    #     )\n",
        "    #     wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "    #     with logging_redirect_tqdm():\n",
        "    #         logging.info(\n",
        "    #             f\"step {step}: train loss {train_loss:.4f}, val loss {val_loss:.4f}\"\n",
        "    #         )\n",
        "    #         logging.info(generate(generate_len, block_size, model, device))\n",
        "\n",
        "    # Sample batch\n",
        "    xb, yb = get_batch(train_tokens, block_size, batch_size, device, y=train_labels)\n",
        "    _, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a319f13-c2a1-42db-9225-9335d253e698",
      "metadata": {
        "tags": [],
        "id": "5a319f13-c2a1-42db-9225-9335d253e698"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}