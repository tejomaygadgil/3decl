{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb314d06-f20c-4e2a-8f68-ebcc7b9e75e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e3eea84-3019-4ce1-bd46-6fc758323db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import initialize, compose\n",
    "import hydra\n",
    "from greek_accentuation.characters import strip_accents, strip_breathing\n",
    "\n",
    "from cgpos.utils.util import import_pkl, export_pkl, get_abs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945faf51-fbe6-4be0-a2be-8f42843ccc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset hydra\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "# Load hydra params\n",
    "initialize(\"../conf/\", version_base=None)\n",
    "config = compose(config_name='main')\n",
    "# Init logger\n",
    "logging.basicConfig(level=logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2405ed92-b0b4-4102-a594-1640227d2762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cgpos.utils.util:Importing /home/tejomay/cgpos/data/processed/perseus_featurized.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_raw = import_pkl(config.perseus.featurized)\n",
    "# Clean\n",
    "data = [word for word in data_raw if 'pos' in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab092cb-d4ec-418e-b081-c3fc31adb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(sequence, n):\n",
    "    \"\"\"\n",
    "    Generate ngram from a sequence of tokens.\n",
    "    \"\"\"\n",
    "    len_sequence = len(sequence)\n",
    "    n_passes = max(1, len_sequence - n + 1)\n",
    "    return (tuple(sequence[i:(i + n)]) for i in range(n_passes))\n",
    "\n",
    "def ngram_bos(data, n=1):\n",
    "    \"\"\"\n",
    "    Generate n-gram bag of syllables for given data.\n",
    "    \"\"\"\n",
    "    bos = defaultdict(Counter)\n",
    "    for word in data:\n",
    "        pos = word['pos']\n",
    "        syllables = word['syllables']\n",
    "        for gram in ngram(syllables, n):\n",
    "            bos[gram][pos] +=1 \n",
    "    return bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37807e5e-d0a3-41f6-9c88-10caa589bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of syllables\n",
    "def ngram_bos_model(data, n=2, train=0.8, verbose=True, seed=20):\n",
    "    \"\"\"\n",
    "    Implement n-gram bag of syllable model.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"N-gram bag of syllables model: n={n}\")\n",
    "    \n",
    "    # Train test split\n",
    "    random.seed(seed)\n",
    "    shuffled = random.sample(data, len(data))\n",
    "    train_ind = int(len(data) * train)\n",
    "    train_data = shuffled[:train_ind] \n",
    "    test_data = shuffled[train_ind:]\n",
    "\n",
    "    if verbose:\n",
    "        logger.info(f\"Train-test split {train}: (train={len(train_data)}, test={len(test_data)}) [seed={seed}]\")\n",
    "\n",
    "    # Train\n",
    "    train_grams = {}\n",
    "    for i in range(1, n + 1):\n",
    "        train_gram = ngram_bos(train_data, n=i)\n",
    "        train_grams[i] = train_gram\n",
    "\n",
    "    # Test\n",
    "    for word in test_data:\n",
    "        gram_dist = Counter()\n",
    "        for gram in ngram(word['syllables'], n):\n",
    "            if (gram in train_grams[n]):\n",
    "                gram_dist += train_grams[n][gram]\n",
    "            else:\n",
    "                for subgram in ngram(gram, n - 1):\n",
    "                    if (subgram in train_grams[n - 1]):\n",
    "                        gram_dist += train_grams[n - 1][subgram]\n",
    "                    else:\n",
    "                        for subsubgram in ngram(subgram, n - 2):\n",
    "                            if (subsubgram in train_grams[n - 2]):\n",
    "                                gram_dist += train_grams[n - 2][subsubgram]\n",
    "        if gram_dist:\n",
    "            pos_pred = max(gram_dist, key=gram_dist.get)\n",
    "        else:\n",
    "            pos_pred = None\n",
    "        word['pos_pred'] = pos_pred\n",
    "        word['gram_dist'] = gram_dist\n",
    "\n",
    "    accuracy = sum([(word['pos'] == word['pos_pred']) for word in test_data]) / len(test_data)\n",
    "    \n",
    "    if verbose:\n",
    "        logger.info(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    results = {\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data,\n",
    "        'train_grams': train_grams,\n",
    "        'accuracy': accuracy,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def cv(data, model=ngram_bos_model, folds=10, **kwargs):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"Running {folds}-fold CV on n-gram bag-of-syllables model:\")\n",
    "    results = []\n",
    "    accuracies = []\n",
    "    for i in range(1, folds + 1):\n",
    "        logger.info(f\"Training fold {i}:\")\n",
    "        seed = random.randint(1, 2**10)\n",
    "        result = model(data, seed=seed, **kwargs)\n",
    "        accuracy = result['accuracy']\n",
    "        results.append(result)\n",
    "        accuracies.append(accuracy)\n",
    "    logger.info(f\"{folds}-fold CV results: accuracy {np.mean(accuracies) * 100:.2f}%, std {np.std(accuracies):.2f}\")\n",
    "    accuracies.append(accuracy)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abac6d9d-f2d0-4d1c-a6d8-2aa5155bac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:N-gram bag of syllables model: n=3\n",
      "INFO:__main__:Train-test split 0.8: (train=439916, test=109980) [seed=20]\n",
      "INFO:__main__:Accuracy: 89.38%\n"
     ]
    }
   ],
   "source": [
    "results = ngram_bos_model(data, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eb1d7be-f9d6-407b-90ec-460df91cc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results['test_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "227612e0-93a3-478a-b0fb-b28ee02e8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = get_abs_dir(config.data.results + '/additive_ngram_bos_output.csv')\n",
    "df[['uid', 'form', 'norm', 'syllables', 'pos', 'pos_pred', 'gram_dist']].to_csv(export_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
